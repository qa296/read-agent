"""
Agent æ ¸å¿ƒé€»è¾‘ - å®ç° ReAct æ¨¡å¼å’Œ Memory æœºåˆ¶
"""

import json
import os
import re
from typing import List, Dict, Optional, Any, Callable
from dataclasses import dataclass, field
from datetime import datetime

from src.searcher import CodeSearcher


@dataclass
class Memory:
    """è®°å¿†ç»“æ„"""
    file_path: str
    overview: str = ""
    key_definitions: List[str] = field(default_factory=list)
    core_logic: str = ""
    dependencies: List[str] = field(default_factory=list)
    needed_info: str = ""

    def to_dict(self) -> Dict:
        return {
            "file": self.file_path,
            "overview": self.overview,
            "key_definitions": self.key_definitions,
            "core_logic": self.core_logic,
            "dependencies": self.dependencies,
            "needed_info": self.needed_info
        }

    def to_string(self) -> str:
        parts = [f"ğŸ“„ {self.file_path}"]
        if self.overview:
            parts.append(f"æ¦‚è¿°: {self.overview}")
        if self.key_definitions:
            parts.append(f"å…³é”®å®šä¹‰: {'; '.join(self.key_definitions)}")
        if self.core_logic:
            parts.append(f"æ ¸å¿ƒé€»è¾‘: {self.core_logic}")
        if self.dependencies:
            parts.append(f"ä¾èµ–: {' -> '.join(self.dependencies)}")
        if self.needed_info:
            parts.append(f"å¾…éªŒè¯: {self.needed_info}")
        return "\n".join(parts)


class ToolExecutor:
    """å·¥å…·æ‰§è¡Œå™¨"""

    def __init__(self, searcher: CodeSearcher):
        self.searcher = searcher
        self._tool_registry: Dict[str, Callable] = {}

    def register_tools(self):
        """æ³¨å†Œå¯ç”¨å·¥å…·"""
        self._tool_registry = {
            "read_file": self._read_file,
            "find_files": self._find_files,
            "search_code": self._search_code,
            "find_by_ext": self._find_by_ext,
            "list_dir": self._list_dir,
            "get_file_info": self._get_file_info,
        }

    def execute_tool(self, tool_name: str, **kwargs) -> Dict:
        """æ‰§è¡Œå·¥å…·"""
        if tool_name not in self._tool_registry:
            return {"error": f"æœªçŸ¥å·¥å…·: {tool_name}"}

        try:
            result = self._tool_registry[tool_name](**kwargs)
            return {"success": True, "tool": tool_name, "result": result}
        except Exception as e:
            return {"success": False, "tool": tool_name, "error": str(e)}

    def _read_file(self, path: str, max_lines: int = 500, start_line: int = 1) -> Dict:
        return self.searcher.read_file(path, max_lines, start_line)

    def _find_files(self, pattern: str = "*", max_results: int = 20) -> List[str]:
        return self.searcher.find_files(pattern, max_results)

    def _search_code(self, keyword: str, extensions: str = "*", max_results: int = 20) -> List[Dict]:
        return self.searcher.search_code(keyword, extensions, max_results)

    def _find_by_ext(self, extensions: str = "py", max_results: int = 20) -> List[str]:
        return self.searcher.find_by_ext(extensions, max_results)

    def _list_dir(self, path: str = ".") -> Dict:
        return self.searcher.list_dir(path)

    def _get_file_info(self, path: str) -> Dict:
        return self.searcher.get_file_info(path)

    def get_available_tools(self) -> List[Dict]:
        """è·å–å¯ç”¨å·¥å…·åˆ—è¡¨"""
        return [
            {
                "name": "read_file",
                "description": "è¯»å–æ–‡ä»¶å†…å®¹",
                "params": {
                    "path": {"type": "string", "description": "æ–‡ä»¶è·¯å¾„"},
                    "max_lines": {"type": "integer", "description": "æœ€å¤§è¡Œæ•°", "default": 500},
                    "start_line": {"type": "integer", "description": "èµ·å§‹è¡Œå·", "default": 1}
                }
            },
            {
                "name": "find_files",
                "description": "æŒ‰æ–‡ä»¶åæ¨¡å¼æŸ¥æ‰¾æ–‡ä»¶",
                "params": {
                    "pattern": {"type": "string", "description": "æ–‡ä»¶åæ¨¡å¼ï¼Œå¦‚ *.py"},
                    "max_results": {"type": "integer", "description": "æœ€å¤§ç»“æœæ•°", "default": 20}
                }
            },
            {
                "name": "search_code",
                "description": "æœç´¢ä»£ç å†…å®¹",
                "params": {
                    "keyword": {"type": "string", "description": "æœç´¢å…³é”®è¯"},
                    "extensions": {"type": "string", "description": "æ–‡ä»¶æ‰©å±•å", "default": "*"},
                    "max_results": {"type": "integer", "description": "æœ€å¤§ç»“æœæ•°", "default": 20}
                }
            },
            {
                "name": "find_by_ext",
                "description": "æŒ‰æ‰©å±•åæŸ¥æ‰¾æ–‡ä»¶",
                "params": {
                    "extensions": {"type": "string", "description": "æ‰©å±•åï¼Œå¦‚ py,js"},
                    "max_results": {"type": "integer", "description": "æœ€å¤§ç»“æœæ•°", "default": 20}
                }
            },
            {
                "name": "list_dir",
                "description": "åˆ—å‡ºç›®å½•å†…å®¹",
                "params": {
                    "path": {"type": "string", "description": "ç›®å½•è·¯å¾„", "default": "."}
                }
            },
            {
                "name": "get_file_info",
                "description": "è·å–æ–‡ä»¶ä¿¡æ¯",
                "params": {
                    "path": {"type": "string", "description": "æ–‡ä»¶è·¯å¾„"}
                }
            }
        ]


class ReadAgent:
    """Read Agent ä¸»ç±»"""

    def __init__(
        self,
        code_dir: str = ".",
        api_key: Optional[str] = None,
        base_url: Optional[str] = None,
        model: str = "gpt-4",
        max_steps: int = 10,
        stream_output: bool = True
    ):
        self.searcher = CodeSearcher(code_dir)
        self.tool_executor = ToolExecutor(self.searcher)
        self.tool_executor.register_tools()

        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.base_url = base_url or os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
        self.model = model or os.getenv("OPENAI_MODEL", "gpt-4")
        self.max_steps = max_steps
        self.stream_output = stream_output

        self.conversation_history: List[Dict] = []
        self.memories: List[Memory] = []
        self.steps: List[Dict] = []

    def _extract_thought_action(self, response: str) -> tuple:
        """ä»å“åº”ä¸­æå– Thought å’Œ Action"""
        thought = ""
        action = ""
        action_args = {}

        # æå– Thought
        thought_match = re.search(r"Thought:\s*(.+?)(?:\nAction:|$)", response, re.DOTALL)
        if thought_match:
            thought = thought_match.group(1).strip()

        # æå– Action
        action_match = re.search(r"Action:\s*(\w+)\(([^)]*)\)", response)
        if action_match:
            action = action_match.group(1)
            args_str = action_match.group(2)

            # è§£æå‚æ•°
            args_pattern = r'(\w+)="([^"]*)"'
            for match in re.finditer(args_pattern, args_str):
                action_args[match.group(1)] = match.group(2)

        return thought, action, action_args

    def _extract_final_answer(self, response: str) -> tuple:
        """æå–æœ€ç»ˆç­”æ¡ˆå’Œ Memory"""
        answer = ""
        memory_data = None

        # æå– Final Answer
        answer_match = re.search(r"Final Answer:\s*(.+?)(?:\nMemory:|$)", response, re.DOTALL)
        if answer_match:
            answer = answer_match.group(1).strip()

        # æå– Memory
        memory_match = re.search(
            r"Memory:\s*file:\s*(.+?)\noverview:\s*(.+?)\nkey_definitions:\s*(.+?)\ncore_logic:\s*(.+?)\ndependencies:\s*(.+?)\nneeded_info:\s*(.+?)(?:\n\n|$)",
            response,
            re.DOTALL
        )
        if memory_match:
            memory_data = {
                "file": memory_match.group(1).strip(),
                "overview": memory_match.group(2).strip(),
                "key_definitions": [k.strip() for k in memory_match.group(3).split(",") if k.strip()],
                "core_logic": memory_match.group(4).strip(),
                "dependencies": [d.strip() for d in memory_match.group(5).split(",") if d.strip()],
                "needed_info": memory_match.group(6).strip()
            }

        return answer, memory_data

    def _call_llm(self, messages: List[Dict], max_tokens: int = 4000) -> str:
        """è°ƒç”¨ LLM APIï¼ˆæ”¯æŒæµå¼è¾“å‡ºï¼‰"""
        import urllib.request
        import urllib.error

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }

        data = {
            "model": self.model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": 0.7,
            "stream": True  # å¯ç”¨æµå¼è¾“å‡º
        }

        full_content = ""
        try:
            req = urllib.request.Request(
                f"{self.base_url}/chat/completions",
                headers=headers,
                data=json.dumps(data).encode("utf-8"),
                method="POST"
            )

            with urllib.request.urlopen(req, timeout=60) as response:
                for line in response:
                    line = line.decode("utf-8").strip()
                    if not line.startswith("data: "):
                        continue
                    if line == "data: [DONE]":
                        break

                    data_str = line[6:]  # ç§»é™¤ "data: " å‰ç¼€
                    try:
                        chunk = json.loads(data_str)
                        if chunk.get("choices") and len(chunk["choices"]) > 0:
                            delta = chunk["choices"][0].get("delta", {})
                            content = delta.get("content", "")
                            if content:
                                # æµå¼è¾“å‡ºæ€è€ƒå†…å®¹
                                if self.stream_output:
                                    print(content, end="", flush=True)
                                full_content += content
                    except json.JSONDecodeError:
                        continue

            # æµå¼è¾“å‡ºå®Œæˆåæ¢è¡Œ
            if self.stream_output:
                print()

            return full_content

        except urllib.error.HTTPError as e:
            error_body = e.read().decode("utf-8") if e.fp else ""
            raise Exception(f"API é”™è¯¯: {e.code} - {error_body}")
        except Exception as e:
            raise Exception(f"è¯·æ±‚é”™è¯¯: {str(e)}")

    def _build_system_prompt(self) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        tools_info = json.dumps(self.tool_executor.get_available_tools(), ensure_ascii=False, indent=2)

        memories_info = ""
        if self.memories:
            memories_info = "\n\nå·²è¯»å–æ–‡ä»¶çš„ Memory:\n" + "\n".join(
                [m.to_string() for m in self.memories]
            )

        return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç é˜…è¯»åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·ç†è§£ä»£ç åº“ã€‚

## å·¥ä½œæµç¨‹
1. åˆ†æç”¨æˆ·é—®é¢˜
2. æ€è€ƒéœ€è¦çš„å·¥å…·
3. æ‰§è¡Œå·¥å…·è°ƒç”¨
4. è§‚å¯Ÿç»“æœ
5. å¦‚æœè¯»å–äº†æ–‡ä»¶ï¼Œè¯·åœ¨ Final Answer ä¸­ç”Ÿæˆè¯¥æ–‡ä»¶çš„ Memory
6. åç»­æ­¥éª¤ä½¿ç”¨ Memory æ›¿ä»£åŸæ–‡ï¼Œé¿å…ä¸Šä¸‹æ–‡è†¨èƒ€

## å¯ç”¨å·¥å…·
{tools_info}

## é‡è¦è§„åˆ™
- åªåœ¨å½“å‰æ­¥éª¤ä½¿ç”¨è¯»å–çš„æ–‡ä»¶åŸæ–‡è¿›è¡Œåˆ†æ
- åˆ†æå®Œæˆååœ¨ Final Answer ä¸­ç”Ÿæˆ Memoryï¼ˆåŒ…å«æ–‡ä»¶æ¦‚è¿°ã€å…³é”®å®šä¹‰ã€æ ¸å¿ƒé€»è¾‘ã€ä¾èµ–å…³ç³»ã€å¾…éªŒè¯ä¿¡æ¯ï¼‰
- ä¸è¦é¢å¤–è°ƒç”¨ LLM æå– Memory
- åç»­æ­¥éª¤ä½¿ç”¨ Memory æ›¿ä»£åŸæ–‡
- æœ€å¤šä½¿ç”¨ {self.max_steps} æ­¥å®Œæˆä¸€ä¸ªé—®é¢˜
- å§‹ç»ˆç”¨ä¸­æ–‡å›ç­”{memories_info}"""

    def _format_step(self, step: Dict) -> str:
        """æ ¼å¼åŒ–æ­¥éª¤æ˜¾ç¤º"""
        parts = [f"\nğŸ”„ æ­¥éª¤ {step['step']}"]

        if step.get("thought"):
            parts.append(f"ğŸ’­ æ€è€ƒ: {step['thought']}")

        if step.get("action"):
            parts.append(f"ğŸ”§ è¡ŒåŠ¨: {step['action']}")

        if step.get("observation"):
            obs = step['observation']
            if isinstance(obs, dict):
                if obs.get("success"):
                    parts.append(f"âœ… ç»“æœ: {json.dumps(obs.get('result'), ensure_ascii=False, indent=2)[:500]}")
                else:
                    parts.append(f"âŒ é”™è¯¯: {obs.get('error')}")
            else:
                parts.append(f"ğŸ“‹ ç»“æœ: {str(obs)[:500]}")

        return "\n".join(parts)

    def _think_and_act(self, user_question: str) -> str:
        """æ€è€ƒå¹¶æ‰§è¡Œè¡ŒåŠ¨"""
        # æ„å»ºæ¶ˆæ¯
        messages = [
            {"role": "system", "content": self._build_system_prompt()}
        ]

        # æ·»åŠ å¯¹è¯å†å²
        for msg in self.conversation_history:
            messages.append(msg)

        # æ·»åŠ å½“å‰é—®é¢˜
        messages.append({
            "role": "user",
            "content": f"""{user_question}

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›å¤ï¼š
Thought: ä½ å¯¹è¿™ä¸ªé—®é¢˜çš„æ€è€ƒ
Action: å·¥å…·å(å‚æ•°="å€¼")

å¦‚æœå¯ä»¥å›ç­”é—®é¢˜ï¼Œè¯·ç”¨ï¼š
Thought: å·²æœ‰è¶³å¤Ÿä¿¡æ¯å›ç­”
Final Answer: ä½ çš„å›ç­”

å¦‚æœè¯»å–äº†æ–‡ä»¶ï¼Œè¯·åœ¨ Final Answer æœ«å°¾æ·»åŠ  Memoryï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
Memory:
file: æ–‡ä»¶å
overview: æ–‡ä»¶æ¦‚è¿°ï¼ˆä¸€å¥è¯è¯´è¿™ä¸ªæ–‡ä»¶æ˜¯åšä»€ä¹ˆçš„ï¼‰
key_definitions: å…³é”®å‡½æ•°/ç±»å®šä¹‰åˆ—è¡¨ï¼ˆé€—å·åˆ†éš”ï¼‰
core_logic: æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ç®€è¿°
dependencies: ä¾èµ–çš„å…¶ä»–æ¨¡å—/æ–‡ä»¶
needed_info: è¿˜éœ€è¦äº†è§£ä»€ä¹ˆä¿¡æ¯

ç¤ºä¾‹ï¼š
Final Answer: ç”¨æˆ·è®¤è¯é€šè¿‡ JWT å®ç°...
Memory:
file: auth.py
overview: å¤„ç†ç”¨æˆ·è®¤è¯é€»è¾‘
key_definitions: login(), logout(), JWTValidator
core_logic: é€šè¿‡ JWT token éªŒè¯ç”¨æˆ·èº«ä»½
dependencies: user.py, utils/token.py
needed_info:"""
        })

        return self._call_llm(messages, max_tokens=2000)

    def ask(self, question: str) -> str:
        """
        è¯¢é—®å…³äºä»£ç åº“çš„é—®é¢˜

        Args:
            question: ç”¨æˆ·é—®é¢˜

        Returns:
            Agent çš„å›ç­”
        """
        self.steps = []
        self.conversation_history.append({"role": "user", "content": question})

        # æµå¼æ¨¡å¼ä¸‹è¾“å‡ºæ ‡é¢˜
        if self.stream_output:
            print(f"\n{'='*60}")
            print(f"ğŸ¤” é—®é¢˜: {question}")
            print(f"\nğŸ“ åˆ†æè¿‡ç¨‹:")

        for step in range(1, self.max_steps + 1):
            # è·å–æ€è€ƒå’Œè¡ŒåŠ¨
            response = self._think_and_act(question)

            # è®°å½•æ­¥éª¤
            step_info = {"step": step, "raw_response": response}
            thought, action, action_args = self._extract_thought_action(response)
            step_info["thought"] = thought
            step_info["action_str"] = f"{action}({action_args})" if action else ""

            # æ£€æŸ¥æ˜¯å¦æœ‰æœ€ç»ˆç­”æ¡ˆå’Œ Memory
            final_answer, memory_data = self._extract_final_answer(response)

            # å¦‚æœæœ‰ Memoryï¼Œä¿å­˜åˆ°åˆ—è¡¨
            if memory_data:
                path = memory_data.get("file", "")
                if path:
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    existing = [m for m in self.memories if m.file_path == path]
                    if existing:
                        self.memories.remove(existing[0])
                    # åˆ›å»ºæ–°çš„ Memory å¯¹è±¡
                    memory = Memory(
                        file_path=path,
                        overview=memory_data.get("overview", ""),
                        key_definitions=memory_data.get("key_definitions", []),
                        core_logic=memory_data.get("core_logic", ""),
                        dependencies=memory_data.get("dependencies", []),
                        needed_info=memory_data.get("needed_info", "")
                    )
                    self.memories.append(memory)

            if final_answer:
                step_info["final_answer"] = final_answer
                self.steps.append(step_info)
                self.conversation_history.append({"role": "assistant", "content": final_answer})

                # æµå¼è¾“å‡ºæœ€ç»ˆç­”æ¡ˆ
                if self.stream_output:
                    print(f"\n{'='*60}")
                    print(f"ğŸ’¡ å›ç­”:\n{final_answer}")
                    return ""
                else:
                    return self._format_output(question, final_answer)

            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            if action:
                step_info["action"] = f"{action}({action_args})"
                tool_result = self.tool_executor.execute_tool(action, **action_args)
                step_info["observation"] = tool_result

                # æµå¼è¾“å‡ºå½“å‰æ­¥éª¤
                if self.stream_output:
                    print(self._format_step(step_info))

                # å°†è§‚å¯Ÿç»“æœæ·»åŠ åˆ°å¯¹è¯
                self.conversation_history.append({
                    "role": "user",
                    "content": f"Observation: {json.dumps(tool_result, ensure_ascii=False)}"
                })

            self.steps.append(step_info)

        # è¶…æ—¶ï¼Œè¿”å›æœ€åçš„ç»“æœ
        if self.stream_output:
            print(f"\n{'='*60}")
            print(f"ğŸ’¡ å›ç­”:\nå·²è¾¾åˆ°æœ€å¤§æ­¥éª¤æ•°é™åˆ¶ï¼Œè¯·å°è¯•æ›´å…·ä½“çš„é—®é¢˜ã€‚")
            return ""
        else:
            return self._format_output(question, "å·²è¾¾åˆ°æœ€å¤§æ­¥éª¤æ•°é™åˆ¶ï¼Œè¯·å°è¯•æ›´å…·ä½“çš„é—®é¢˜ã€‚")

    def _format_output(self, question: str, answer: str) -> str:
        """æ ¼å¼åŒ–è¾“å‡º"""
        output = [f"\n{'='*60}"]
        output.append(f"ğŸ¤” é—®é¢˜: {question}")
        output.append(f"\nğŸ“ åˆ†æè¿‡ç¨‹:")

        for step_info in self.steps:
            output.append(self._format_step(step_info))

        output.append(f"\n{'='*60}")
        output.append(f"ğŸ’¡ å›ç­”:\n{answer}")

        return "\n".join(output)

    def clear_memory(self):
        """æ¸…ç©º Memory"""
        self.memories = []

    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.conversation_history = []
        self.memories = []
        self.steps = []

    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "conversation_length": len(self.conversation_history),
            "memory_count": len(self.memories),
            "total_steps": len(self.steps),
            "code_dir": str(self.searcher.root_dir)
        }
